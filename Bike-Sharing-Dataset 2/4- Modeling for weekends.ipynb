{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from My_Functions import * \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score,roc_curve\n",
    "from sklearn.model_selection import train_test_split, KFold,StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict,validation_curve\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer, RobustScaler,PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, boxcox_normmax\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator , MultipleLocator\n",
    "##from matplotlib import XAxis\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, LabelBinarizer,StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression, OrthogonalMatchingPursuit\n",
    "from sklearn.model_selection import train_test_split , TimeSeriesSplit, GridSearchCV \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import plotly.tools as tls\n",
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='Furqan92', api_key='22DfVN5rFRg79OYygN5h')\n",
    "import plotly.plotly as py\n",
    "from sklearn.decomposition import PCA\n",
    "from pandas import DataFrame \n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "random_seed = 504\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To automatically reload the function file \n",
    "%load_ext autoreload\n",
    "%aimport My_Functions\n",
    "%run My_Functions.py\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "we_h=pd.read_csv('./weekends1_holi_data_prepared.csv')\n",
    "we_h['dteday']=pd.to_datetime(we_h['dteday'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset 2011 -> 2012Q3 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_2011_2012Q2 = we_h[we_h['dteday'] < datetime.datetime(2012, 7, 1, 0, 0)].drop(['cnt','casual','registered','dteday'],axis=1)## NONE OF THst_EM IN DATA\n",
    "Y_cnt_train_2011_2012Q2 =we_h['cnt'][we_h['dteday'] < datetime.datetime(2012, 7, 1, 0, 0)]\n",
    "\n",
    "X_Test_2012Q3 = we_h[(we_h['dteday'] >= datetime.datetime(2012, 7, 1, 0, 0)) & (we_h['dteday'] <= datetime.datetime(2012, 9, 30, 0, 0))].drop(['cnt','casual','registered','dteday'],axis=1)## NONE OF THEM IN DATA\n",
    "Y_cnt_test_2012Q3 =we_h['cnt'][(we_h['dteday'] >= datetime.datetime(2012, 7, 1, 0, 0)) & (we_h['dteday'] <= datetime.datetime(2012, 9, 30, 0, 0))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression w/ GS for *Weekends* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833325057136417"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Linear Regression\n",
    "lm_parameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True]}\n",
    "\n",
    "lm = GridSearchCV(LinearRegression(),\n",
    "                                 param_grid=lm_parameters,\n",
    "                                 cv=tscv,return_train_score=True)\n",
    "\n",
    "lm.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "# lm.cv_results_\n",
    "lm_predictions = lm.predict(X_Test_2012Q3)\n",
    "lm.score(X_Test_2012Q3, Y_cnt_test_2012Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest w/ GS for *weekends* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8570826212022598"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_parameters = {'n_estimators': [10, 30 ,40,100],\n",
    "                                             'bootstrap': [True ,False],\n",
    "                                             'max_depth': [80, 100 ,120 ],\n",
    "                                             'max_features': ['log2', 16, 32 ],\n",
    "                                             'min_samples_leaf': [2,  5 , 8],\n",
    "                                             'min_samples_split': [ 10 , 8 , 15 , 18],\n",
    "                                            'random_state':[random_seed],\n",
    "                                            'criterion':['mse']}\n",
    "rf = GridSearchCV(RandomForestRegressor(),\n",
    "                                 param_grid= RF_parameters,\n",
    "                                 cv=tscv)\n",
    "\n",
    "rf.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "# rf.cv_results_\n",
    "rf_predictions = lm.predict(X_Test_2012Q3)\n",
    "rf.score(X_Test_2012Q3, Y_cnt_test_2012Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors regressor w/ GS for *Weekends* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169627172541623"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_parameters = {'n_neighbors':[1, 5,10,15, 30 ],'weights':['uniform'], 'algorithm':['auto'],'leaf_size':[5 ,10, 20,30],\n",
    "                  'p':[1,2,3],'metric':['minkowski']}\n",
    "knn = GridSearchCV(KNeighborsRegressor(),\n",
    "                                 param_grid=knn_parameters,\n",
    "                                 cv=tscv,return_train_score=True)\n",
    "knn.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "# rf.cv_results_\n",
    "knn_predictions = knn.predict(X_Test_2012Q3)\n",
    "knn.score(X_Test_2012Q3, Y_cnt_test_2012Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector regressor w/ GS for *Weekends* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svr = GridSearchCV(SVR(), cv=tscv,\n",
    "#                    param_grid={\"kernel\" : ['linear', 'rbf', 'poly'],\n",
    "#                        \"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "#                                \"gamma\": np.logspace(-2, 2, 5)})\n",
    "\n",
    "# svr.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "# # rf.cv_results_\n",
    "# svr_predictions = svr.predict(X_Test_2012Q3)\n",
    "# svr.score(X_Test_2012Q3, Y_cnt_test_2012Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost regressor w/ GS for *Weekends* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 15.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8879889040783053"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_grid = {'learning_rate': [0.01, 0.1], \n",
    "          'max_depth': [4,8,12],\n",
    "          'min_child_weight': [3,5,10,20,35,50],\n",
    "          'subsample': [0.5, 0.75],\n",
    "          'colsample_bytree': [0.5, 0.75],\n",
    "          'n_estimators': [100, 300],\n",
    "              'random_state':[random_seed]\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "xg = GridSearchCV(model,\n",
    "                    param_grid = param_grid,\n",
    "                    cv = tscv,\n",
    "                    n_jobs = -1,\n",
    "                    scoring = 'r2',\n",
    "                    verbose=True)\n",
    "xg.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "xg_predictions = xg.predict(X_Test_2012Q3)\n",
    "xg.score(X_Test_2012Q3, Y_cnt_test_2012Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking predictions from LR and Random Forest to test on 2012Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR and Random Forest predictions\n",
    "combinedPredictions = pd.DataFrame({'lm_predictions':lm_predictions,'rf_predictions':rf_predictions,'xg_predictions':xg_predictions })\n",
    "\n",
    "# Concat original data\n",
    "X_Test_2012Q3.reset_index(drop=True,inplace=True)\n",
    "combinedPredictions = pd.concat([combinedPredictions,X_Test_2012Q3], axis=1)\n",
    "\n",
    "# Target data\n",
    "combinedPredictionsTarget = pd.DataFrame({'target':Y_cnt_test_2012Q3})\n",
    "\n",
    "#Reset indices\n",
    "combinedPredictions.reset_index(drop=True,inplace=True)\n",
    "combinedPredictionsTarget.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Q4 data and concat it with its level-0 predctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Q4 data\n",
    "X_Test_Q4 = we_h[(we_h['dteday'] >= datetime.datetime(2012, 9, 30, 0, 0)) & (we_h['dteday'] <= datetime.datetime(2012, 12, 31, 0, 0))].drop(['cnt','casual','registered','dteday'],axis=1)## NONE OF THEM IN DATA\n",
    "Y_cnt_test_Q4 =we_h['cnt'][(we_h['dteday'] >= datetime.datetime(2012, 9, 30, 0, 0)) & (we_h['dteday'] <= datetime.datetime(2012, 12, 31, 0, 0))]\n",
    "oringal_cnt = Y_cnt_test_Q4\n",
    "\n",
    "#get level-0 predictions for Q4 data\n",
    "Q4_lm_predictions = pd.DataFrame(lm.predict(X_Test_Q4), columns=[\"lm_predictions\"])\n",
    "Q4_rf_predictions = pd.DataFrame(rf.predict(X_Test_Q4), columns=[\"rf_predictions\"])\n",
    "##Q4_knn_predications = pd.DataFrame(knn.predict(X_Test_Q4), columns=[\"knn_predications\"])\n",
    "Q4_xg_predictions = pd.DataFrame(xg.predict(X_Test_Q4), columns=[\"xg_predictions\"])\n",
    "\n",
    "X_Test_Q4.reset_index(drop=True,inplace=True)\n",
    "Q4_lm_predictions.reset_index(drop=True,inplace=True)\n",
    "Q4_rf_predictions.reset_index(drop=True,inplace=True)\n",
    "\n",
    "Q4_xg_predictions.reset_index(drop=True,inplace=True)\n",
    "Y_cnt_test_Q4.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#concat Q4 with level-0 predictions \n",
    "X_Test_Q4_with_predictions = pd.concat([Q4_lm_predictions, Q4_rf_predictions,Q4_xg_predictions,X_Test_Q4], axis=1)\n",
    "Y_cnt_test_Q4 = pd.DataFrame({\"target\": Y_cnt_test_Q4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8785830145250169"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lm.score(X_Test_Q4, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8496221562020154"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_Test_Q4, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7577913883377447"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_Test_Q4, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8905392281141818"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.score(X_Test_Q4, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   39.6s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8580293752201731"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_grid = {'learning_rate': [0.01, 0.1], \n",
    "          'max_depth': [4,8,12],\n",
    "          'min_child_weight': [3,5,10,20,35,50],\n",
    "          'subsample': [0.5, 0.75],\n",
    "          'colsample_bytree': [0.5, 0.75],\n",
    "          'n_estimators': [100, 300],\n",
    "              'random_state':[random_seed]\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "xg1 = GridSearchCV(model,\n",
    "                    param_grid = param_grid,\n",
    "                    cv = tscv,\n",
    "                    n_jobs = -1,\n",
    "                    scoring = 'r2',\n",
    "                    verbose=True)\n",
    "\n",
    "xg1.fit(combinedPredictions, combinedPredictionsTarget)\n",
    "xg1_predictions = xg1.predict(X_Test_Q4_with_predictions)\n",
    "xg1.score(X_Test_Q4_with_predictions, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The score decreased drastically so after some research Stochastic Gradient Descent seemed like an appropriate model to try in stacking because it also act on errors using lasso and ridge and elastic net \n",
    "penalty and has learning rate , in fact it gave a better score then XGBoost but still not morew then the level 0 XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent: tried after XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8801300973656445"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search - this will take about 1 minute.\n",
    "param_grid = {\n",
    "    'alpha': 10.0 ** -np.arange(1, 7),\n",
    "    'loss': ['squared_loss', 'huber', 'epsilon_insensitive'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "}\n",
    "clf = GridSearchCV(SGDRegressor(), param_grid)\n",
    "clf.fit(combinedPredictions, combinedPredictionsTarget)\n",
    "clf_predictions = clf.predict(X_Test_Q4_with_predictions)\n",
    "clf.score(X_Test_Q4_with_predictions, Y_cnt_test_Q4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we saw that our score decreased after the stacking so it seemed appropriate to go with the XGBoost level 0 model \n",
    "(This was not mentioned in the presentation because a random seed wasnt fixed )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_predictions=pd.read_csv('pred_working.csv')\n",
    "work_predictions.columns = ['dteday','prediction','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_work_predictions = pd.concat((pd.DataFrame(xg.predict(X_Test_Q4)) , Y_cnt_test_Q4), axis=1)\n",
    "not_work_predictions.columns = ['prediction','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last r2 score for the predictions is :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8970919438033946"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The last r2 score for the predictions is :')\n",
    "r2score(np.concatenate((not_work_predictions['target'],\n",
    "                         work_predictions['target'])),\n",
    "         np.concatenate((not_work_predictions['prediction'],\n",
    "                         work_predictions['prediction'])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = we_h['dteday'][(we_h['dteday'] >= datetime.datetime(2012, 9, 30, 0, 0)) & (we_h['dteday'] <= datetime.datetime(2012, 12, 31, 0, 0))]\n",
    "date=pd.to_datetime(date, format='%Y-%m-%d')\n",
    "date.reset_index(drop=True,inplace=True)\n",
    "work_predictions.reset_index(drop=True,inplace=True)\n",
    "not_work_predictions=pd.concat([date,not_work_predictions],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_predictions.set_index('dteday')\n",
    "not_work_predictions.set_index('dteday')\n",
    "\n",
    "combined=work_predictions.append(not_work_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~Furqan92/4.embed\" height=\"525px\" width=\"800px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = combined.melt('dteday', var_name='cols',  value_name='vals')\n",
    "df[\"dteday\"]=df[\"dteday\"].map(lambda x:  pd.to_datetime(x))\n",
    "mpl_fig = plt.figure()\n",
    "ax= plt.axes()\n",
    "\n",
    "sns.lineplot(x=\"dteday\", y=\"vals\", hue='cols', data=df)\n",
    "\n",
    "plotly_fig=tls.mpl_to_plotly(mpl_fig)\n",
    "plotly_fig['layout']['xaxis'] = {\n",
    "   'tickmode': 'auto',\n",
    "   'nticks': 3\n",
    "    }\n",
    "plotly_fig['layout']['showlegend'] = False\n",
    "plotly_fig['layout'] = {'width':800}\n",
    "plotly_fig['layout']['title'] = 'Predictions'\n",
    "py.iplot(plotly_fig,filename='Predictions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
