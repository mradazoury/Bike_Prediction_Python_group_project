{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Washington DC Biking data | Hourly Bike Count Prediction\n",
    "\n",
    "# 3. Modeling for WorkingDays\n",
    "MBD O-1-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# To automatically reload the function file \n",
    "%load_ext autoreload\n",
    "%aimport My_Functions\n",
    "%run My_Functions.py\n",
    "%autoreload 1\n",
    "%matplotlib inline\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To automatically reload the function file \n",
    "%load_ext autoreload\n",
    "%aimport My_Functions\n",
    "%run My_Functions.py\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "wd_h=pd.read_csv('./workingdays_data_prepared.csv')\n",
    "wd_h['dteday']=pd.to_datetime(wd_h['dteday'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset 2011 -> 2012Q3 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing the dataset in one year and a half and Q3 iun order to be able to train level 0 AND PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_2011_2012Q2 = wd_h[wd_h['dteday'] < datetime.datetime(2012, 7, 5, 0, 0)].drop(['cnt','casual','registered','dteday'],axis=1)## NONE OF THst_EM IN DATA\n",
    "Y_cnt_train_2011_2012Q2 =wd_h['cnt'][wd_h['dteday'] < datetime.datetime(2012, 7, 5, 0, 0)]\n",
    "\n",
    "X_Test_2012Q3 = wd_h[(wd_h['dteday'] >= datetime.datetime(2012, 7, 5, 0, 0)) & (wd_h['dteday'] <= datetime.datetime(2012, 9, 30, 0, 0))].drop(['cnt','casual','registered','dteday'],axis=1)## NONE OF THEM IN DATA\n",
    "Y_cnt_test_2012Q3 =wd_h['cnt'][(wd_h['dteday'] >= datetime.datetime(2012, 7, 5, 0, 0)) & (wd_h['dteday'] <= datetime.datetime(2012, 9, 30, 0, 0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression w/ GS for *Weekdays* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the simplest model on Q3 , even though the score is high here this is the prediction for Q3 (FALL) , as we saw in the EDA FALL SPRING AND SUMMER behaved in the same way but winter was a bit different so we can say that the model learned from 5 similar season and we would not expect the same score for Q4 ( winter ) . This clearly an indicator that the feature created previously have helped our model to learn more about the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.941401943285146"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Linear Regression\n",
    "lm_parameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True]}\n",
    "\n",
    "lm = GridSearchCV(LinearRegression(),\n",
    "                                 param_grid=lm_parameters,\n",
    "                                 cv=tscv ,return_train_score=True)\n",
    "\n",
    "lm.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "lm.cv_results_\n",
    "lm_predictions = lm.predict(X_Test_2012Q3)\n",
    "lm.score(X_Test_2012Q3, Y_cnt_test_2012Q3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest w/ GS for *Weekdays* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying linear regressor we tried random forest with a large grid search in order to make sure that we are using the best possible parameters for the model \n",
    "Our expectations were to have a higher score then the linear model but we did not, This could be due to the fact that there are alot of linearly correlated target to the data such as the new weather variable created and the \n",
    "mean_per_hour which reflects a direct linear correlation of the past target in the same hour.\n",
    "Random forest acts best when the data is clearly partitione in groups such as the Rush_Hour and Is_Daylight that clearly differentiate the different target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9289808963621973"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_parameters = {'n_estimators': [10, 30 ,100],\n",
    "                                             'bootstrap': [True],\n",
    "                                             'max_depth': [80, 100 ],\n",
    "                                             'max_features': ['sqrt',16 ,32],\n",
    "                                             'min_samples_leaf': [2,  5 , 8],\n",
    "                                             'min_samples_split': [ 10 , 8 , 15],\n",
    "                                            'random_state':[random_seed],\n",
    "                                            'criterion':['mse']}\n",
    "rf = GridSearchCV(RandomForestRegressor(),\n",
    "                                 param_grid= RF_parameters,\n",
    "                                 cv=tscv)\n",
    "\n",
    "rf.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "rf.cv_results_\n",
    "rf_predictions = lm.predict(X_Test_2012Q3)\n",
    "rf.score(X_Test_2012Q3, Y_cnt_test_2012Q3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors regressor w/ GS for *Weekends* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying the basic model we went into the more exotic ones , here the KNN claculate the difference between the differernt point and tries to classsif them \n",
    "in groups and then compare these groups to the target and trie to get teh cclosest estimated number.\n",
    "The bases of trying this model and why it seemed like it would make sense to us is because in our EDA it looked like there are multiple waya to cluster the differnret hours \n",
    "either by weather , hr ,season or even day  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9211277733616634"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_parameters = {'n_neighbors':[5,10,15],'weights':['uniform'], 'algorithm':['auto'],'leaf_size':[10, 20,30],\n",
    "                  'p':[1,2,3],'metric':['minkowski']}\n",
    "knn = GridSearchCV(KNeighborsRegressor(),\n",
    "                                 param_grid=knn_parameters,\n",
    "                                 cv=tscv,return_train_score=True)\n",
    "knn.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "# rf.cv_results_\n",
    "knn_predictions = knn.predict(X_Test_2012Q3)\n",
    "knn.score(X_Test_2012Q3, Y_cnt_test_2012Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector regressor w/ GS for *Weekends* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is known for it complexity and the amount of time it takes oto run but we wanted to give it a try , so instead of using a wide range forthe gridsearch we just used one of the basic kernels  and diffeerent values for C and gamma \n",
    "the resulat were Bad , this maybe due to choice of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7455187270287198"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "svr = GridSearchCV(SVR(kernel='rbf', gamma=0.1), cv=tscv,\n",
    "                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "                               \"gamma\": np.logspace(-2, 2, 5)})\n",
    "\n",
    "svr.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "# rf.cv_results_\n",
    "svr_predictions = svr.predict(X_Test_2012Q3)\n",
    "svr.score(X_Test_2012Q3, Y_cnt_test_2012Q3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost regressor w/ GS for *Weekends* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost is known for winning most of the kaggle competitions so we thought it was worth a shot , specialy since we know that this algorithm work on the errors of a tree algorithm and improves on it\n",
    " the Grid Search used wasa wide enough in terms of parameter and gave back the best scores between all the algortihms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  9.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 17.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 29.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed: 37.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.934419033223012"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_grid = {'learning_rate': [0.01, 0.1], \n",
    "          'max_depth': [4,8,12],\n",
    "          'min_child_weight': [3,5,10,20,35,50],\n",
    "          'subsample': [0.5, 0.75],\n",
    "          'colsample_bytree': [0.5, 0.75],\n",
    "          'n_estimators': [100, 300], 'random_state':[random_seed]\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "xg = GridSearchCV(model,\n",
    "                    param_grid = param_grid,\n",
    "                    cv = tscv,\n",
    "                    n_jobs = -1,\n",
    "                    scoring = 'r2',\n",
    "                    verbose=True)\n",
    "xg.fit(X_Train_2011_2012Q2, Y_cnt_train_2011_2012Q2)\n",
    "xg_predictions = xg.predict(X_Test_2012Q3)\n",
    "xg.score(X_Test_2012Q3, Y_cnt_test_2012Q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking predictions from LR and Random Forest and xgboost to test on 2012Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A level further was taken and the predictions of the top 3 previous algortihms ( Random Forest , Linear Regression , and XGBoost ) on Q3 were attached to the \n",
    "initial Q3 data for training a new algorithm on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR and Random Forest predictions\n",
    "combinedPredictions = pd.DataFrame({'lm_predictions':lm_predictions,'rf_predictions':rf_predictions,'xg_predictions':xg_predictions })\n",
    "\n",
    "# Concat original data\n",
    "X_Test_2012Q3.reset_index(drop=True,inplace=True)\n",
    "combinedPredictions = pd.concat([combinedPredictions,X_Test_2012Q3], axis=1)\n",
    "\n",
    "# Target data\n",
    "combinedPredictionsTarget = pd.DataFrame({'target':Y_cnt_test_2012Q3})\n",
    "\n",
    "#Reset indices\n",
    "combinedPredictions.reset_index(drop=True,inplace=True)\n",
    "combinedPredictionsTarget.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Q4 data and concat it with its level-0 predctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the original Q4 data and adding to it the predictions from the 3 algortihms chosen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Q4 data\n",
    "X_Test_Q4 = wd_h[(wd_h['dteday'] >= datetime.datetime(2012, 10, 1, 0, 0)) & (wd_h['dteday'] <= datetime.datetime(2012, 12, 31, 0, 0))].drop(['cnt','casual','registered','dteday'],axis=1)## NONE OF THEM IN DATA\n",
    "Y_cnt_test_Q4 =wd_h['cnt'][(wd_h['dteday'] >= datetime.datetime(2012, 10, 1, 0, 0)) & (wd_h['dteday'] <= datetime.datetime(2012, 12, 31, 0, 0))]\n",
    "oringal_cnt = Y_cnt_test_Q4\n",
    "\n",
    "#get level-0 predictions for Q4 data\n",
    "Q4_lm_predictions = pd.DataFrame(lm.predict(X_Test_Q4), columns=[\"lm_predictions\"])\n",
    "Q4_rf_predictions = pd.DataFrame(rf.predict(X_Test_Q4), columns=[\"rf_predictions\"])\n",
    "Q4_xg_predictions = pd.DataFrame(xg.predict(X_Test_Q4), columns=[\"xg_predictions\"])\n",
    "\n",
    "X_Test_Q4.reset_index(drop=True,inplace=True)\n",
    "Q4_lm_predictions.reset_index(drop=True,inplace=True)\n",
    "Q4_rf_predictions.reset_index(drop=True,inplace=True)\n",
    "Q4_xg_predictions.reset_index(drop=True,inplace=True)\n",
    "Y_cnt_test_Q4.reset_index(drop=True,inplace=True)\n",
    "\n",
    "#concat Q4 with level-0 predictions \n",
    "X_Test_Q4_with_predictions = pd.concat([Q4_lm_predictions, Q4_rf_predictions,Q4_xg_predictions, X_Test_Q4 ], axis=1)\n",
    "Y_cnt_test_Q4 = pd.DataFrame({\"target\": Y_cnt_test_Q4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Here are the scores of the trained algorithms on the Q4 data in order to be able to compare our initial results to the stacking ones later on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839966859540709"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.score(X_Test_Q4, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715926918607073"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_Test_Q4, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8980765759281988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg.score(X_Test_Q4, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Nearest Neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8340477314724115"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_Test_Q4, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Regressor :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7077025873956615"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.score(X_Test_Q4, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost regressor w/ GS for Level 1 *Weekends* for 2011 -> 2012Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the scores above  XGBoost will be retrained on the 3rd Quarter with the predictions of the best 3 models and will be tested on Q4  with the predictions on Q4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 204 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 454 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 804 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1254 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9010145680993351"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [0.01, 0.1], \n",
    "          'max_depth': [4,8,12],\n",
    "          'min_child_weight': [3,5,10,20,35,50],\n",
    "          'subsample': [0.5, 0.75],\n",
    "          'colsample_bytree': [0.5, 0.75],\n",
    "          'n_estimators': [100, 300], 'random_state':[random_seed]\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "xg1 = GridSearchCV(model,\n",
    "                    param_grid = param_grid,\n",
    "                    cv = tscv,\n",
    "                    n_jobs = -1,\n",
    "                    scoring = 'explained_variance',\n",
    "                    verbose=True)\n",
    "\n",
    "xg1.fit(combinedPredictions, combinedPredictionsTarget)\n",
    "xg1_predictions = xg1.predict(X_Test_Q4_with_predictions)\n",
    "xg1.score(X_Test_Q4_with_predictions, Y_cnt_test_Q4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final score for the prediction of Q4 workingdays : 0.9022288970285075\n",
    "\n",
    "Things that could have increased the score more :\n",
    "    - CHoosing the right amount of features for every algorithms , but this was very computationaly heavy , since trying an RFECV with the already time ocnsuming algorithms would take too long\n",
    "    - Increasing the gridsearch or maybe using Bayesian Optimization \n",
    "Things we thought would increase our score that we tried but did not work :\n",
    "    - Running the level 1 algorithm only on the predictions without the initial data \n",
    "    - Doing stacking in a way that would use the prediction of the TimeSeriesCross Validation and then retrain the level 0 algorithm with more data \n",
    "    (it did not work because the prediction in each fold used was being outputed from a different \"Train\" of the same algorithm , and the prediction for test data would only be predicted by the training of one of the folds, \n",
    "    this means that what the level1 algorithm is trying to learn from the predicted values would be different in each fold )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_predictions  = pd.concat( (pd.DataFrame(xg1.predict(X_Test_Q4_with_predictions)), Y_cnt_test_Q4), axis =1 )\n",
    "dates = wd_h['dteday'][(wd_h['dteday'] >= datetime.datetime(2012, 9, 30, 0, 0)) & (wd_h['dteday'] <= datetime.datetime(2012, 12, 31, 0, 0))]\n",
    "dates=pd.to_datetime(dates, format='%Y-%m-%d')\n",
    "dates.reset_index(drop=True,inplace=True)\n",
    "work_predictions.reset_index(drop=True,inplace=True)\n",
    "full_wd=pd.concat([dates,work_predictions],axis=1)\n",
    "full_wd.to_csv(\"pred_working.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
